{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Week 8: Acquiring and Manipulating Videos\n",
    "\n",
    "<font size=\"6\"> Laboratory 7 </font> <br>\n",
    "<font size=\"3\"> Last updated August 17, 2022 </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## <span style=\"color:orange;\"> 00. Content </span>\n",
    "\n",
    "<font size=\"5\"> Mathematics </font>\n",
    "- N/A\n",
    "    \n",
    "<font size=\"5\"> Programming Skills </font>\n",
    "- Using Software Documentation\n",
    "- OpenCV (cv2)\n",
    "    \n",
    "<font size=\"5\"> Embedded Systems </font>\n",
    "- Thonny and MicroPython\n",
    "\n",
    "## <span style=\"color:orange;\"> 0. Required Hardware </span>\n",
    "- Microcontroller: Raspberry Pi Pico\n",
    "- Breadboard\n",
    "- USB connector\n",
    "- Camera (Arducam HM01B0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3 style=\"background-color:lightblue\"> Write your name and email below: </h3>\n",
    "\n",
    "**Name:** me \n",
    "\n",
    "**Email:** me @purdue.edu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:orange;\"> 1. Reading Videos with OpenCV </span>\n",
    "\n",
    "In this lab, we will be using a Python library called OpenCV (cv2). From the [official documentation](https://docs.opencv.org/4.x/d1/dfb/intro.html), \"OpenCV is an open-source library that includes several hundreds of computer vision algorithms.\" Today, we will mostly be using it to read and display modified video frames, and we will be doing the \"vision\" in computer vision manually with our own functions.\n",
    "\n",
    "Run the following cell to read in the video file. Using `vid.read()`, returns two values: the Boolean varible `success`, which is `True` if the frame was read without any errors, and `frame` which is as it sounds the image that is captured from the video. The camera hardware you will connect to your Pico can only return grayscale images, so we are converting each frame to grayscale using the function `cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)`. For speed in later computations, it is helpful to reduce the frame size. Here, we've scaled down each frame by a factor of 4.\n",
    "\n",
    "Running the cell will cause a separate window to pop up, displaying the smaller, grayscale video. After reading in the whole video, the separate window will close automatically; you can override this by pressing the \"Q\" key on your keyboard.\n",
    "\n",
    "Download the video file we'll be using for this lab: [test_vid.mov](https://github.com/TheDataScienceLabs/DataLab_Multivariate_Calculus/blob/main/book/labs/2_Video_Labs/test_vid.mov). This is a video from Youtube showing a bouncing ball.\n",
    "<!-- COPYRIGHTS???? It would be best to make our own. -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vid = cv2.VideoCapture('test_vid.mov') \n",
    "height = vid.get(cv2.CAP_PROP_FRAME_HEIGHT)\n",
    "width  = vid.get(cv2.CAP_PROP_FRAME_WIDTH) \n",
    "scale = 0.25\n",
    "new_size = (int(width*scale),int(height*scale))\n",
    "\n",
    "while vid.isOpened():\n",
    "    success, frame = vid.read()\n",
    "    if not success:\n",
    "        print(\"Unable to read frame. Exiting ...\")\n",
    "        break\n",
    "    frame = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    frame = cv2.resize(frame,dsize=new_size)\n",
    "    cv2.imshow('frame', frame)\n",
    "    if cv2.waitKey(25) == ord('q'): # press Q on keyboard to stop\n",
    "        break\n",
    "vid.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style=\"color:red\"> Exercise 1 </span>\n",
    "\n",
    "Open and watch the above video again, this time scaled down each frame by a factor of 8. How much less CPU time does it take to play the video, compared to when you only scaled it down by a factor 4?\n",
    "\n",
    "\n",
    "<h3 style=\"background-color:lightblue\"> Write Answers for Exercise 1 Below </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:orange;\"> 2. Modifying Videos </span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style=\"color:red\"> Exercise 2 </span>\n",
    "\n",
    "Read the [documentation](https://docs.opencv.org/2.4/modules/highgui/doc/user_interface.html?highlight=waitkey) for the `waitKey` function.\n",
    "\n",
    "**Part 1**\n",
    "\n",
    "Play the video slower than its original playback speed.\n",
    "\n",
    "**Part 2** \n",
    "\n",
    "Play the video faster than its original playback speed.\n",
    "\n",
    "<h3 style=\"background-color:lightblue\"> Write Answers for Exercise 2 Part 1 Below </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3 style=\"background-color:lightblue\"> Write Answers for Exercise 2 Part 2 Below </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style=\"color:red\"> Exercise 3 </span>\n",
    "\n",
    "Play the video backward.\n",
    "\n",
    "<h3 style=\"background-color:lightblue\"> Write Answers for Exercise 3 Below </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style=\"color:red\"> Exercise 4 </span>\n",
    "\n",
    "**Part 1**\n",
    "\n",
    "Flip the video's visuals over the y-axis.\n",
    "\n",
    "**Part 2**\n",
    "\n",
    "Flip the video's visuals over the x-axis.\n",
    "\n",
    "<h3 style=\"background-color:lightblue\"> Write Answers for Exercise 4 Part 1 Below </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3 style=\"background-color:lightblue\"> Write Answers for Exercise 4 Part 2 Below </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Being able to extract specific frames from a video is a useful skill. It can be used, for example, to trim the ends of the video or to remove a section in the middle."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style=\"color:red\"> Exercise 5 </span>\n",
    "\n",
    "Extract the first 200 frames of the video. \n",
    "\n",
    "<h3 style=\"background-color:lightblue\"> Write Answers for Exercise 5 Below </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:orange;\"> 3. Connecting the Camera </span>\n",
    "\n",
    "This time, we will be recording our own videos using the Arducam HM01B0, which is a small camera that can be hooked up to the Pico. \n",
    "\n",
    "### Wiring Instructions\n",
    "\n",
    "Please make sure your microcontroller is not plugged to the computer while you are wiring things together. Ask the instructor if you are unsure about your wiring. Use your jumper wires to make the following connections.\n",
    "\n",
    "| HM01B0 | Pico |\n",
    "|--------|------|\n",
    "| VCC    | 3V3  |\n",
    "| SCL    | GP5  |\n",
    "| SDA    | GP4  |\n",
    "| VSYNC  | GP16 |\n",
    "| HREF   | GP15 |\n",
    "| PCLK   | GP14 |\n",
    "| DO     | GP6  |\n",
    "| GND    | GND  |\n",
    "\n",
    "<!-- ![img](camera.jpg)\n",
    "\n",
    "*Wiring the Arducam HM01B0 camera* \n",
    "\n",
    "![img](camerawiring.jpg)\n",
    "\n",
    "*Connections to the PICO on breadboard* -->\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After ensuring that the wiring is correct, hold down the BOOTSEL button on the Pico and plug it in. Download [arducam.uf2](https://github.com/TheDataScienceLabs/DataLab_Multivariate_Calculus/blob/main/book/labs/2_Video_Labs/arducam.uf2) and copy it onto the Pico's drive, which should have popped up in your folders as an option. The Pico should automatically disconnect once the file has transferred, then its LED will start blinking rapidly. \n",
    "\n",
    "Once the Pico has been successfully connected, run the following cell to make sure we have detected the Pico successfully."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import serial\n",
    "from serial.tools import list_ports\n",
    "\n",
    "PICO_HWID = \"2E8A\"\n",
    "\n",
    "\n",
    "def get_pico_port():\n",
    "    pico_ports = list(list_ports.grep(PICO_HWID))\n",
    "    if len(pico_ports) == 0:\n",
    "        raise Exception(\n",
    "            \"No Raspberry Pi Pico was detected. Check to make sure it is plugged in, and that no other programs are accessing it\"\n",
    "        )\n",
    "    return pico_ports[0].device\n",
    "\n",
    "\n",
    "print(\"Here are all the serial devices detected:\")\n",
    "for port in list_ports.comports():\n",
    "    print(port.device, port.hwid)\n",
    "\n",
    "port = get_pico_port()\n",
    "print(f\"\\nselected port {port} as most likely to have a raspberry pi pico\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Capturing a still image\n",
    "\n",
    "Now that the Pico and camera have been connected, run the following cell to get a still image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "buffer = bytearray(96 * 96)\n",
    "img = np.zeros(shape=(96, 96), dtype=\"uint8\")\n",
    "\n",
    "with serial.Serial(port, timeout=1) as s:\n",
    "    s.read_until(b\"\\x55\\xAA\")\n",
    "    s.readinto(buffer)\n",
    "    img.flat[::-1] = buffer\n",
    "\n",
    "plt.imshow(img, cmap=\"gray\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style=\"color:red\"> Exercise 6 </span>\n",
    "\n",
    "Use the camera to acquire an image of yourself with your hand up, and an image of yourself with your hands down. Use these two frames (you are welcome to use more than 2 frames if desired) to create a video of yourself moving your hands up and down.\n",
    "\n",
    "<h3 style=\"background-color:lightblue\"> Write Answers for Exercise 6 Below </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Streaming video\n",
    "\n",
    "Now that we can capture a still image, the next goal is to stream a video. Both cells will have to be run before the video is streamed to your screen. After running the first one, a still image should pop up but once you run the second cell it should start streaming what your camera is seeing in real-time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib widget\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "render = ax.imshow(img, cmap='gray')\n",
    "plt.show(block=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    with serial.Serial(port, timeout=1) as s:\n",
    "        while True:\n",
    "            s.read_until(b\"\\x55\\xAA\")\n",
    "            s.readinto(buffer)\n",
    "            img.flat[::-1] = buffer\n",
    "            render.set_data(img)\n",
    "            fig.canvas.draw()\n",
    "except KeyboardInterrupt:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When you are done, you will have to hit the `Interrupt Kernel` button, which can found at the top of the screen (the stop symbol) or under Kernel."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:orange;\"> 4. Modifying Your Own Video </span>\n",
    "\n",
    "Now that you are able to capture your own video, you will try the same modifications you made on the prerecorded videos on the one you recorded."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style=\"color:red\"> Exercise 7 </span>\n",
    "\n",
    "Capture and save a video using the camera.\n",
    "\n",
    "**Part 1:** Either trim both ends of the video or remove a section in the middle.\n",
    "\n",
    "**Part 2:** Record a second video. Splice the two videos together.\n",
    "\n",
    "**Part 3:** Pick an editing function we haven't mentioned (e.g., adding text, video filters, etc.) and try it out on either the prerecorded video or the one you recorded using the camera.\n",
    "\n",
    "\n",
    "<h3 style=\"background-color:lightblue\"> Write Answers for Exercise 7 Below </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# how to save a video\n",
    "fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "out = cv2.VideoWriter()\n",
    "fps = 30\n",
    "capsize = # (width,height) of the images added to in the video\n",
    "success = out.open('my_video.mp4v', fourcc, fps, capsize, True)\n",
    "print(success)\n",
    "for frame in []: #list of frames\n",
    "    out.write(frame)\n",
    "out.release()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:green\"> Reflection </span>\n",
    "\n",
    "__1. What parts of the lab, if any, do you feel you did well? <br>\n",
    "2. What are some things you learned today? <br>\n",
    "3. Are there any topics that could use more clarification? <br>\n",
    "4. Do you have any suggestions on parts of the lab to improve?__\n",
    "\n",
    "<h3 style=\"background-color:lightblue\"> Write Answers for the Reflection Below </h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.5 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "vscode": {
   "interpreter": {
    "hash": "5733b5ebf5ecec2b002a59c36710d44decb4334b28aff8074b4cca610e6649ad"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
